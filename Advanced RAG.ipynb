{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Advanced RAG"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Naive Retrieval-Augmented Generation (RAG) Overview\n",
    "\n",
    "Naive RAG involves three primary phases:\n",
    "\n",
    "1. **Indexing**: \n",
    "   - Prepares the document collection for retrieval by cleaning and extracting relevant information from each document. This phase involves parsind and preprocessing documents, chunking the parsed documents, using an embedding model to generate vectors out of the chunks, and storing them into a vector database.\n",
    "   \n",
    "2. **Retrieval**: \n",
    "   - Converts the user query into a vector representation using the embedding model.\n",
    "   - Compares the vectorized query with the vectors stored in the vector database to retrieve the most relevant chunks. \n",
    "\n",
    "3. **Generation**: \n",
    "   - Augments the user query with the retrieved chunks into a single prompt.\n",
    "   - Generates an answer to the user query using a language model based on this combined information."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Naive RAG Pitfalls\n",
    "\n",
    "Naive RAG presents two main types of challenges:\n",
    "1. **Retrieval challenges**: selection of irrelevant chunks to query, missing crucial information.\n",
    "2. **Generation challenges**: the LLM struggles with hallucination and presents issues with relevance in its output.\n",
    "\n",
    "These challenges occur mainly due to:\n",
    "\n",
    "1. **Limited contextual understanding**:\n",
    "   - Because naive RAG focus on **keyword matching** or basic semantic search, it retrieves irrelevant or partially relevant documents to the query. For example, a query like \"*...the impact of climate change on polar bears*\" would retrieve documents related with *climate change* and *polars bears* but not documents that talk about both *climate change* and *polars bears*.\n",
    "\n",
    "2. **Inconsistent Relevance and Quality of Retrieved Documents**  \n",
    "   - Naive RAG may struggle with effective document ranking, which can result in irrelevant or low-quality inputs being fed into the model.\n",
    "\n",
    "3. **Poor Integration Between Retrieval and Generation**  \n",
    "   - In Naive RAG, the retriever and generator operate independently, often leading to a lack of coordination between retrieval results and generation context.\n",
    "\n",
    "4. **Inefficient Handling of Large-Scale Data**  \n",
    "   - Standard retrieval methods can be inefficient at scale, making it challenging for Naive RAG to manage large datasets. This can cause delays in finding relevant documents or result in critical information being missed due to ineffective indexing.\n",
    "\n",
    "5. **Lack of Robustness and Adaptability**  \n",
    "   - Naive RAG lacks mechanisms to handle ambiguous or complex queries effectively. When queries contain multiple or nuanced questions, Naive RAG struggles to adapt, often failing to provide comprehensive answers due to its limited flexibility."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Advanced RAG Techniques\n",
    "Advanced RAG techniques introduces improvement to overcome the limitations of Naive RAG, focusing on enhancing the retrieval quality.\n",
    "\n",
    "1. Pre-retrieval\n",
    "    - It improves the indexing structure and user's query, by organizing the indexes better and adding extra information. \n",
    "\n",
    "2. Pos-retrieval\n",
    "    - We combine the data obtained during the pre-retrieval phase with the original query. This could involve re-raking to highlight the most important content. \n",
    "\n",
    "### Query Expansion\n",
    "This technique uses the LLM to generate an hallucinated answer to the query and get relevant context. Next, we retrieve documents from the vector database given on the original query. \n",
    "\n",
    "The use cases of query expansions are:\n",
    "- information retrieval: we improve the quality of the information that is retrieved\n",
    "- question answering systems\n",
    "- e-commerce search\n",
    "- academic research\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
